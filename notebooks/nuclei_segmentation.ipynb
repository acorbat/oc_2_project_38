{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclei Segmentation\n",
    "\n",
    "Let's begin with nuclei segmentation.\n",
    "We can either segment the DAPI channel and then filter out the healthy nuclei, segment only the healthy nuclei or go for the ISL1 channel that has the label for the nuclei of interest.\n",
    "\n",
    "Let's select an image and then crop out a small piece of it to make testing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from czifile import CziFile\n",
    "from napari import Viewer\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data/NS#1_Healhty-DAPI, WGA, ISL1, G3BP.czi\")\n",
    "image_handle = CziFile(DATA_DIR)\n",
    "img = np.squeeze(image_handle.asarray())[3, :, 1000:1500, 1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = {\n",
    "    values_dict[\"Id\"]: values_dict[\"Value\"] * 10**6\n",
    "    for values_dict in image_handle.metadata(raw=False)[\"ImageDocument\"][\"Metadata\"][\n",
    "        \"Scaling\"\n",
    "    ][\"Items\"][\"Distance\"]\n",
    "}\n",
    "spacing = (scale[\"Z\"], scale[\"Y\"], scale[\"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Equalization\n",
    "\n",
    "We should first try some histogram equalization as the intensity values ar every different across planes.\n",
    "I am not sure this will solve some of the saturation problems though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (50 / scale[\"Z\"], 50 / scale[\"Y\"], 50 / scale[\"X\"])\n",
    "\n",
    "equalized_img = equalize_adapthist(\n",
    "    img,\n",
    "    kernel_size=kernel,\n",
    "    clip_limit=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'equalized_img' at 0x7d90a657f680>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(img, scale=spacing, visible=False)\n",
    "viewer.add_image(equalized_img, scale=spacing, visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellpose\n",
    "\n",
    "Let's begin by trying out cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:56:06,682 [INFO] WRITING LOG OUTPUT TO /home/biif/.cellpose/run.log\n",
      "2024-07-01 11:56:06,682 [INFO] \n",
      "cellpose version: \t3.0.10 \n",
      "platform:       \tlinux \n",
      "python version: \t3.12.4 \n",
      "torch version:  \t2.3.1+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Logger cellpose.io (INFO)>, PosixPath('/home/biif/.cellpose/run.log'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellpose import models  # noqa\n",
    "from cellpose.io import logger_setup  # noqa\n",
    "\n",
    "logger_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:56:06,696 [INFO] >>>> using CPU\n",
      "2024-07-01 11:56:06,699 [INFO] >> nuclei << model set to be used\n",
      "2024-07-01 11:56:06,842 [INFO] >>>> loading model /home/biif/.cellpose/models/nucleitorch_0\n",
      "2024-07-01 11:56:06,984 [INFO] >>>> model diam_mean =  17.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "model = models.Cellpose(model_type=\"nuclei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a couple attempts with several algorithms, I thought there might be issues with all the saturated nuclei.\n",
    "To circunvent this, I made a mask for those pixels, calculated the distance transform and added this to the original image in order to have some values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturated_mask = img[3] == 255\n",
    "distance_saturated = np.asarray(\n",
    "    [distance_transform_edt(this_plane) for this_plane in saturated_mask]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.astype(float)\n",
    "img[3] = img[3] + 10 * distance_saturated\n",
    "img[3] = img[3] / (np.max(img[3]) + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.505521313330107\n"
     ]
    }
   ],
   "source": [
    "anisotropy = scale[\"Z\"] / scale[\"X\"]\n",
    "print(anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.86719385289848\n"
     ]
    }
   ],
   "source": [
    "diameter = 10 / scale[\"X\"]\n",
    "print(diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 13:27:34,043 [INFO] channels set to [0, 0]\n",
      "2024-07-01 13:27:34,045 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2024-07-01 13:27:34,046 [INFO] multi-stack tiff read in as having 110 planes 1 channels\n",
      "2024-07-01 13:27:34,348 [INFO] running YX: 110 planes of size (500, 500)\n",
      "2024-07-01 13:27:34,359 [INFO] 0%|          | 0/4 [00:00<?, ?it/s]\n",
      "2024-07-01 13:27:39,560 [INFO] 25%|##5       | 1/4 [00:05<00:15,  5.20s/it]\n",
      "2024-07-01 13:27:44,518 [INFO] 50%|#####     | 2/4 [00:10<00:10,  5.06s/it]\n",
      "2024-07-01 13:27:48,238 [INFO] 75%|#######5  | 3/4 [00:13<00:04,  4.45s/it]\n",
      "2024-07-01 13:27:52,078 [INFO] 100%|##########| 4/4 [00:17<00:00,  4.21s/it]\n",
      "2024-07-01 13:27:52,079 [INFO] 100%|##########| 4/4 [00:17<00:00,  4.43s/it]\n",
      "2024-07-01 13:27:53,003 [INFO] running ZY: 500 planes of size (110, 500)\n",
      "2024-07-01 13:27:53,052 [INFO] 0%|          | 0/16 [00:00<?, ?it/s]\n",
      "2024-07-01 13:27:57,617 [INFO] 6%|6         | 1/16 [00:04<01:08,  4.56s/it]\n",
      "2024-07-01 13:28:01,695 [INFO] 12%|#2        | 2/16 [00:08<00:59,  4.28s/it]\n",
      "2024-07-01 13:28:05,936 [INFO] 19%|#8        | 3/16 [00:12<00:55,  4.26s/it]\n",
      "2024-07-01 13:28:09,702 [INFO] 25%|##5       | 4/16 [00:16<00:48,  4.07s/it]\n",
      "2024-07-01 13:28:13,967 [INFO] 31%|###1      | 5/16 [00:20<00:45,  4.14s/it]\n",
      "2024-07-01 13:28:17,891 [INFO] 38%|###7      | 6/16 [00:24<00:40,  4.06s/it]\n",
      "2024-07-01 13:28:21,828 [INFO] 44%|####3     | 7/16 [00:28<00:36,  4.02s/it]\n",
      "2024-07-01 13:28:25,738 [INFO] 50%|#####     | 8/16 [00:32<00:31,  3.99s/it]\n",
      "2024-07-01 13:28:29,531 [INFO] 56%|#####6    | 9/16 [00:36<00:27,  3.93s/it]\n",
      "2024-07-01 13:28:33,404 [INFO] 62%|######2   | 10/16 [00:40<00:23,  3.91s/it]\n",
      "2024-07-01 13:28:37,541 [INFO] 69%|######8   | 11/16 [00:44<00:19,  3.98s/it]\n",
      "2024-07-01 13:28:41,477 [INFO] 75%|#######5  | 12/16 [00:48<00:15,  3.97s/it]\n",
      "2024-07-01 13:28:45,581 [INFO] 81%|########1 | 13/16 [00:52<00:12,  4.01s/it]\n",
      "2024-07-01 13:28:49,339 [INFO] 88%|########7 | 14/16 [00:56<00:07,  3.93s/it]\n",
      "2024-07-01 13:28:53,259 [INFO] 94%|#########3| 15/16 [01:00<00:03,  3.93s/it]\n",
      "2024-07-01 13:28:57,117 [INFO] 100%|##########| 16/16 [01:04<00:00,  3.91s/it]\n",
      "2024-07-01 13:28:57,117 [INFO] 100%|##########| 16/16 [01:04<00:00,  4.00s/it]\n",
      "2024-07-01 13:28:59,172 [INFO] running ZX: 500 planes of size (110, 500)\n",
      "2024-07-01 13:28:59,226 [INFO] 0%|          | 0/16 [00:00<?, ?it/s]\n",
      "2024-07-01 13:29:03,062 [INFO] 6%|6         | 1/16 [00:03<00:57,  3.84s/it]\n",
      "2024-07-01 13:29:06,764 [INFO] 12%|#2        | 2/16 [00:07<00:52,  3.76s/it]\n",
      "2024-07-01 13:29:10,349 [INFO] 19%|#8        | 3/16 [00:11<00:47,  3.68s/it]\n",
      "2024-07-01 13:29:14,054 [INFO] 25%|##5       | 4/16 [00:14<00:44,  3.69s/it]\n",
      "2024-07-01 13:29:17,852 [INFO] 31%|###1      | 5/16 [00:18<00:41,  3.73s/it]\n",
      "2024-07-01 13:29:21,590 [INFO] 38%|###7      | 6/16 [00:22<00:37,  3.73s/it]\n",
      "2024-07-01 13:29:25,301 [INFO] 44%|####3     | 7/16 [00:26<00:33,  3.72s/it]\n",
      "2024-07-01 13:29:29,208 [INFO] 50%|#####     | 8/16 [00:29<00:30,  3.78s/it]\n",
      "2024-07-01 13:29:32,884 [INFO] 56%|#####6    | 9/16 [00:33<00:26,  3.75s/it]\n",
      "2024-07-01 13:29:36,682 [INFO] 62%|######2   | 10/16 [00:37<00:22,  3.76s/it]\n",
      "2024-07-01 13:29:40,630 [INFO] 69%|######8   | 11/16 [00:41<00:19,  3.82s/it]\n",
      "2024-07-01 13:29:44,579 [INFO] 75%|#######5  | 12/16 [00:45<00:15,  3.86s/it]\n",
      "2024-07-01 13:29:48,690 [INFO] 81%|########1 | 13/16 [00:49<00:11,  3.94s/it]\n",
      "2024-07-01 13:29:52,988 [INFO] 88%|########7 | 14/16 [00:53<00:08,  4.05s/it]\n",
      "2024-07-01 13:29:57,429 [INFO] 94%|#########3| 15/16 [00:58<00:04,  4.16s/it]\n",
      "2024-07-01 13:30:01,712 [INFO] 100%|##########| 16/16 [01:02<00:00,  4.20s/it]\n",
      "2024-07-01 13:30:01,712 [INFO] 100%|##########| 16/16 [01:02<00:00,  3.91s/it]\n",
      "2024-07-01 13:30:03,293 [INFO] network run in 149.03s\n",
      "2024-07-01 13:30:37,160 [INFO] masks created in 33.87s\n",
      "2024-07-01 13:30:39,838 [INFO] >>>> TOTAL TIME 185.80 sec\n"
     ]
    }
   ],
   "source": [
    "masks, flows, styles, diams = model.eval(\n",
    "    [equalized_img],\n",
    "    batch_size=8,\n",
    "    diameter=diameter,\n",
    "    z_axis=0,\n",
    "    do_3D=True,\n",
    "    channels=[0, 0],\n",
    "    # stitch_threshold=0.5,\n",
    "    normalize=False,\n",
    "    anisotropy=anisotropy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Labels' at 0x7d902175f230>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(img, scale=spacing)\n",
    "viewer.add_labels(masks[0], scale=spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working quite well for some nuclei.\n",
    "Some are still over segmented and some others are not segmented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StarDist\n",
    "\n",
    "Maybe stardist might work.\n",
    "Not tested yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clesperanto Voronoi Otsu\n",
    "\n",
    "Maybe Clesperanto's Voronoi and Otsu labelling works well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto_prototype as cle  # noqa\n",
    "\n",
    "cle.available_device_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gpu = cle.push(img[3])\n",
    "input_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was unable to make clesperanto work on the laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "Let's go for typical thresholding techniques as nuclei might be separated enough to not need watershed or maybe a simple watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max  # noqa\n",
    "from skimage.filters import median, scharr, threshold_otsu  # noqa\n",
    "from skimage.morphology import ball, binary_erosion, dilation, disk  # noqa\n",
    "from skimage.segmentation import watershed  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with some median filtering to enhance a bit the edges.\n",
    "I'm using my own footprint.\n",
    "\n",
    "And then use Otsu thresolding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_resolution = 0.5 / scale[\"X\"]\n",
    "\n",
    "footprint = np.stack(\n",
    "    [\n",
    "        np.zeros_like(disk(pixel_resolution)),\n",
    "        disk(pixel_resolution),\n",
    "        np.zeros_like(disk(pixel_resolution)),\n",
    "    ]\n",
    ")\n",
    "midpoint = footprint.shape[1] // 2\n",
    "footprint[0, midpoint, midpoint] = 1\n",
    "footprint[2, midpoint, midpoint] = 1\n",
    "\n",
    "filtered_image = median(img, footprint=footprint)\n",
    "threshold = threshold_otsu(filtered_image)\n",
    "nuclei = filtered_image > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'nuclei' at 0x7c8d8b380ce0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(img, scale=spacing)\n",
    "viewer.add_labels(nuclei, scale=spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply watershed to get a better separation between nuclei.\n",
    "We will need the seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = np.stack([np.zeros_like(disk(1)), disk(1), np.zeros_like(disk(1))])\n",
    "\n",
    "inter = binary_erosion(nuclei, footprint=footprint)\n",
    "\n",
    "transformed = distance_transform_edt(inter, sampling=spacing)\n",
    "\n",
    "distance_between_nuclei = 1.7  # in um\n",
    "pixel_min_distance = np.floor(distance_between_nuclei / scale[\"X\"]).astype(int)\n",
    "\n",
    "maxima = peak_local_max(transformed, min_distance=pixel_min_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 77\n"
     ]
    }
   ],
   "source": [
    "print(pixel_min_distance, len(maxima))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an image for the edges of the nuclei to limit the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = scharr(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'points' at 0x7c8cf3b9cfb0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(transformed, scale=spacing)\n",
    "viewer.add_image(edges, scale=spacing)\n",
    "viewer.add_points(\n",
    "    maxima,\n",
    "    name=\"points\",\n",
    "    scale=spacing,\n",
    "    size=40,\n",
    "    n_dimensional=True,  # points have 3D \"extent\"\n",
    "    face_color=\"red\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = np.zeros(img.shape, dtype=np.uint32)\n",
    "marker_indices = tuple(np.round(maxima).astype(int).T)\n",
    "markers[marker_indices] = np.arange(len(maxima)) + 1\n",
    "markers = dilation(markers, ball(5))\n",
    "\n",
    "segmented = watershed(\n",
    "    -transformed,\n",
    "    markers,\n",
    "    mask=nuclei,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'segmented' at 0x7c8cb9a0bef0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(img, scale=spacing)\n",
    "viewer.add_labels(segmented, scale=spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not the best and should be improved, but it's not that bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
